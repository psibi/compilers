* Parsing

* Overview

- To parse a computer program, we must first describe the form of
  valid sentences in a language. This formal statement is known as a
  context free grammar (CFG). Because they allow for recursion, CFGs
  are more powerful than regular expressions and can express a richer
  set of structures.
- LL(1) grammars are CFGs that can be evaluated by considering only
  the current rule and next token in the input stream. This property
  makes it easy to write a hand-coded parser known as a recursive
  descent parser.
- LR(1) grammars are more general and more powerful than LL(1). Nearly
  all useful programming languages can be written in LR(1)
  form. However, the parsing algorithm for LR(1) grammars is more
  complex and usually cannot be written by hand. Instead, it is common
  to use a parser generator that will accept an LR(1) grammar and
  automatically generate the parsing code.

* Context Free Grammars

** Terminal

- A *terminal* is a discrete symbol that can appear in the language,
  otherwise known as a *token* from the previous chapter.
- Examples: keywords, operators and identifiers.
- Convention: lower-case letters to represent terminals.

** Non terminal

- A *non-terminal* represents a structure that can occur in a language,
  but is not a literal symbol.
- Examples: declarations, statements and expressions.
- Convention: Upper-case letters to represent non terminals: ~P~ for
  programs, ~S~ for statement, ~E~ for expression etc.

** Sentence

- A *sentence* is a valid sequence of terminals in a language.

** Sentential form

- A *sentential form* is a valid sequence of terminals and non terminals.
- Convention: Greek symbols to represent sentential forms. Example:
  $\alpha$, $\beta$ and $\gamma$ to represent possibly mixed sequence
  of terminals and non-terminals. We will use a seqence like
  $Y_1Y_2...Y_n$ to indicate the individual symbols in a sentential
  form: $Y_i$ may either be a terminal or non terminal.

** Context Free Grammar (CFG)

- A *CFG* is a list of *rules* that formally describe the allowable
  sentences in a language.
- The left hand side of each rule is always a single non-terminal.
- The right hand side of a rule is a *sentential form* that describes
  an allowable form of that non-terminal.
- Example rule: ~A -> xXy~ indicates that the non-terminal ~A~
  represents a terminal ~x~ followed by a non-terminal ~X~ and a
  terminal ~y~.
- The right hand side of a rule can be $\epsilon$ to indicate that the
  rule produces nothing.
- The first rule is special: it is the top level definition of
  aprogram and it's non terminal is known as the *start symbol*

Sample CFG describing expressions involving addition, integers and
identifiers:

[[./images/c4_g2.png][./images/c4_g2.png]]

For brevity, the above grammar can also be written as:

#+begin_example text
E -> E + E | ident | int
#+end_example

** Deriving Sentences

- Each grammar describes a (possibly infinite) set of sentences, which
  is known as the *language* of the grammar.
- To prove that a given sentence is a member of that language, we must
  show that there exists a sequence of rule applications that connects
  the start symbol with the desired sentence.
- A sequence of rule applications is known as a *derivation* and a
  double arrow ($\Rightarrow$) is used to show that one sentential
  form is equal to another by applying a given rule. Example: E
  $\Rightarrow$ int by applying rule 4 of grammer G2.

There are two approaches to derivation:

- top-down: Begin with the start symbol, and then apply rules in the
  CFG to expand non terminals until reaching the desired sentence.
- bottom-up: Begin with the desired setence, and then apply the rules
  backwards until reaching the start symbol.

For example, ~ident + int + int~ is a sentence in this language and
here is one top-down derivation to prove it:

[[./images/c4_g2_top_down.png][./images/c4_g2_top_down.png]]

And similar proof using bottom-up derivation:

[[./images/c4_g2_bottom_up.png]]

It is quite possible for two different grammars to generate the same
language, in which case we describe them as having *weak equivalence*.

** Ambiguous Grammars

- An *ambiguous grammar* allows for more than one possible derivation of
  the same sentence.
- Example: The sentence ~ident + int + int~ can have two derivations:

[[./images/c4_ambigous_grammar.png]]

- Does it matter in the above case ? It certainly does!
- In a language like Java such a sentence ~hello + 5 + 5~ could be
  interpreted as either ~hello55~ or ~hello10~ and that's not good.
- It is possible to re-write a grammer so that it is not ambiguous. In
  the common case of binary operators, we can require that one side of
  the expression be an atomic term (T), like this:

[[./images/c4_g3.png][./images/c4_g3.png]]

- With this change, the grammer is no longer ambigous. But it still
  accepts the same language as Grammer $G_2$
- If you want to construct a grammar with more operators (division,
  muliplication) - then the usual approach is to construct a grammar
  with multiple levels that reflect the intended precedence of
  operators:

[[./images/c4_g4.png][./images/c4_g4.png]]

Grammar which supports two if statements (if-then and if-then-else
variant):

[[./images/c4_g5.png][./images/c4_g5.png]]

The above grammer is ambiguous because it allows for two derivations
of this sentence:

- If E then if E then other else other

There are two derivations of this sentence:

- If E then (if E then other else other)
- If E then (if E then other) else other

* LL Grammars

- LL(1) grammars are a subset of CFGs that are easy to parse with
  simple algorithms.
- A grammar is LL(1) if it can be parsed by considering only one
  non-terminal and the next token in the input stream.

To ensure a grammar is LL(1) we must do the following:

- Remove any ambiguity as shown above.
- Eliminate any left recursion.
- Eliminate any common left prefixes.

** Eliminating Left recursion

LL(1) grammars cannot contain *left recursion* which is a rule of the
form $\text{A} \rightarrow \text{A} \alpha$ or, more generally, any
rule $\text{A} \rightarrow \text{B}\beta$ such that $\text{B}
\Rightarrow \text{A}\gamma$ by some sequence of derivations.

[[./images/c4_elim_left_recur.png][./images/c4_elim_left_recur.png]]

** Eliminating Common Left Prefixes

[[./images/c4_elim_comm_prefix_1.png][./images/c4_elim_comm_prefix_1.png]]

Fixing the grammar will result in:

[[./images/c4_g8.png][./images/c4_g8.png]]

** First and Follow Sets

- In order to construct a complete parser for an LL(1) grammar, we
  must compute two sets, known as ~FIRST~ and ~FOLLOW~.
- Informally, FIRST($\alpha$) indicates the set of terminals
  (including $\epsilon$) that could potentially appear at the
  beginning of any *derivation* of $\alpha$.
- FOLLOW(A) indicates the set of terminals (including $) that could
  potentially occur after any derivation of non-terminal A.
- Given the contents of these two set, the LL(1) parser will always
  know ~which rule to pick next~.

[[./images/c4_first_set.png][./images/c4_first_set.png]]

For non terminals, it says this:

For each rule X $\rightarrow$ $Y_1Y_2...Y_k$ in a grammar G:
- FIRST(X) = a if FIRST(Y_1) = a or (a = FIRST(Y_n) and Y_1...Y_n $\Rightarrow \epsilon$ )

In the above $a = \text{FIRST}(Y_n)$ refers to $n$ where n can be 1,2 or $n$

$Y_1...Y_{n-1} \Rightarrow \epsilon$ \text{means} $\epsilon \in \text{FIRST(}{Y_1)} ... \epsilon \in \text{FIRST}{(Y_{n-1})}$

[[./images/c4_follow_sets.png][./images/c4_follow_sets.png]]

I also found the following source very helpful:
- [[https://www.jambe.co.nz/UNI/FirstAndFollowSets.html][jambe.con.nz source]] (For first sets)
- [[http://www.cs.ecu.edu/karl/5220/spr16/Notes/Top-down/follow.html][cs.ecu.edu source]] [[https://web.archive.org/web/20190203020902/http://www.cs.ecu.edu/karl/5220/spr16/Notes/Top-down/follow.html][Archive link]] (For follow set, example specifically)

I personally found that working out the examples, let me to understand
the above algorithm better. Always going back to the informal
definition above will help you. Now let's see an example:

[[./images/c4_g9.png][./images/c4_g9.png]]

You can also use this [[https://hackage.haskell.org/package/context-free-grammar-0.1.1/docs/Data-Cfg-Analysis.html][Haskell module]] to find them. (Future todo: Write
a blog post about it)

Now for Grammer $G_9$, let's find out the follow sets:

FOLLOW(P) = {$} since P is the start state.

FOLLOW(E)

FOLLOW(E) contains $ since the sentinel form E shows that. (P => E)

E => TE' => FT'E' => (E)T'E'

yields a sentinel form where E is followed by ~)~

FOLLOW(E')

P => E => TE' => E'

So, FOLLOW(E') contains $.

T => FT' => (E)T' => (TE')T'

yields a sentinel form where E' is followed by ~)~

FOLLOW(T)

P => E => TE' => T

So, FOLLOW(T) contains $.

TE' => T+TE'

yields a sentinel form where T is followed by ~+~

T => FT' => (E)T' => (TE')T' => (T)T'

yields a sentinel form where  T is followed by ~)~

FOLLOW(T')

P => E => TE' => FT'E' => FT' => T

We know that FOLLOW(T) contains $

T' => *FT' => *(E)T' => *(+TE')T' => *(+FT')T'

yields a sentinel form where T' is followed by ~)~

FT' => (E)T' => (TE')T' => (FT'E')T' => (FT'+TE)T'

yields a sentinel form wherer T' is followed by ~+~

FOLLOW(F)

P => E => TE' => T => FT' => F

So, Follow(F) contains $

FT' => F*FT'

yields a sentinel form where F is followd by ~*~

TE' => T+TE' => FT'+TE' => F+TE'

yields a sentinel form where F is followed by ~+~

FT' => F*FT' => F*(E)T' => F*(TE')T' => F*(T)T' => F*(FT')T' => F*(F)T'

yiels a sentinel form where F is followed by ~)~

** Recursive Descent Parsing

- LL(1) grammars are very amenable to write simple hand-coded parsers.
- A common approach is a *recursive descent parser* in which there is
  one simple function for each non-terminal in the grammar. The body
  of the function follow the right hand sides of the corresponding
  rules: non-terminal results in a call to another parse function,
  while terminals result in considering the next token.

** Table Driven Parsing

- An LL(1) grammar can also be parsed using generalized table driven
  code.
- A table driven parser requires a grammar, a parse table and a stack
  to represent the current set of non-terminals.
- The *LL(1) parse table* is used to determine which rule should be
  applied for any combination of non-terminal on the stack and next
  token on the input stream.

[[./images/c4_l1_parse_table.png][./images/c4_l1_parse_table.png]]

[[./images/c4_parse_table_g9.png][./images/c4_parse_table_g9.png]]

[[./images/c4_ll_parsing_algo.png][./images/c4_ll_parsing_algo.png]]
