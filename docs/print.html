<!DOCTYPE HTML>
<html lang="en" class="sidebar-visible no-js light">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>Introduction to Compilers and Language Design</title>
        <meta name="robots" content="noindex" />
        <!-- Custom HTML head -->
        <meta content="text/html; charset=utf-8" http-equiv="Content-Type">
        <meta name="description" content="">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff" />

        <link rel="icon" href="favicon.svg">
        <link rel="shortcut icon" href="favicon.png">
        <link rel="stylesheet" href="css/variables.css">
        <link rel="stylesheet" href="css/general.css">
        <link rel="stylesheet" href="css/chrome.css">
        <link rel="stylesheet" href="css/print.css" media="print">
        <!-- Fonts -->
        <link rel="stylesheet" href="FontAwesome/css/font-awesome.css">
        <link rel="stylesheet" href="fonts/fonts.css">
        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" href="highlight.css">
        <link rel="stylesheet" href="tomorrow-night.css">
        <link rel="stylesheet" href="ayu-highlight.css">

        <!-- Custom theme stylesheets -->
    </head>
    <body>
        <!-- Provide site root to javascript -->
        <script type="text/javascript">
            var path_to_root = "";
            var default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? "navy" : "light";
        </script>

        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script type="text/javascript">
            try {
                var theme = localStorage.getItem('mdbook-theme');
                var sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script type="text/javascript">
            var theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            var html = document.querySelector('html');
            html.classList.remove('no-js')
            html.classList.remove('light')
            html.classList.add(theme);
            html.classList.add('js');
        </script>

        <!-- Hide / unhide sidebar before it is displayed -->
        <script type="text/javascript">
            var html = document.querySelector('html');
            var sidebar = 'hidden';
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            }
            html.classList.remove('sidebar-visible');
            html.classList.add("sidebar-" + sidebar);
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <div class="sidebar-scrollbox">
                <ol class="chapter"><li class="chapter-item expanded "><a href="chapter1.html"><strong aria-hidden="true">1.</strong> Chapter 1: Introduction</a></li><li class="chapter-item expanded "><a href="chapter2.html"><strong aria-hidden="true">2.</strong> Chapter 2: A Quick Tour</a></li><li class="chapter-item expanded "><a href="chapter3.html"><strong aria-hidden="true">3.</strong> Chapter 3: Scanning</a></li><li class="chapter-item expanded "><a href="chapter4.html"><strong aria-hidden="true">4.</strong> Chapter 4: Parsing</a></li><li class="chapter-item expanded "><a href="chapter5.html"><strong aria-hidden="true">5.</strong> Chapter 5: Parsing in Practice</a></li></ol>
            </div>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle"></div>
        </nav>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                <div id="menu-bar-hover-placeholder"></div>
                <div id="menu-bar" class="menu-bar sticky bordered">
                    <div class="left-buttons">
                        <button id="sidebar-toggle" class="icon-button" type="button" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                            <i class="fa fa-bars"></i>
                        </button>
                        <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                            <i class="fa fa-paint-brush"></i>
                        </button>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="light">Light (default)</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                        </ul>
                        <button id="search-toggle" class="icon-button" type="button" title="Search. (Shortkey: s)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="S" aria-controls="searchbar">
                            <i class="fa fa-search"></i>
                        </button>
                    </div>

                    <h1 class="menu-title">Introduction to Compilers and Language Design</h1>

                    <div class="right-buttons">
                        <a href="print.html" title="Print this book" aria-label="Print this book">
                            <i id="print-button" class="fa fa-print"></i>
                        </a>
                    </div>
                </div>

                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <input type="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>
                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script type="text/javascript">
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <h1 id="introduction"><a class="header" href="#introduction">Introduction</a></h1>
<p>These are my notes for the book <a href="https://www3.nd.edu/%7Edthain/compilerbook/">Introduction to Compilers and Language
Design</a>.</p>
<p>The source repository for this website is
<a href="https://github.com/psibi/compilers">here</a>. Any pull requests,
contributions welcome!</p>
<h2 id="what-is-a-compiler"><a class="header" href="#what-is-a-compiler">What is a compiler?</a></h2>
<ul>
<li>A compiler translates a program in a source language to a program in
a target language.</li>
<li>A compiler is distinct from an <strong>interpreter</strong>, which reads in a
program and then executes it directly, without emitting a
translation. This is also sometimes known as a <strong>virtual machine</strong>.
Languages like Python and Ruby are typically executed by an
interpreter that reads the source code directly.</li>
<li>Compilers and interpreters are closely related, and it is sometimes
possible to exchange one for the other. For example, Java compilers
translate Java source code into Java bytecode, which is an abstract
form of assembly language. Some implementations of the Java Virtual
Machine work as interpreters that execute one instruction at a time.
Others work by translating the bytecode into local machine code, and
then running the machine code directly. This is known as just in
time compiling or JIT.</li>
</ul>
<h2 id="why-should-you-study-compilers-"><a class="header" href="#why-should-you-study-compilers-">Why should you study compilers ?</a></h2>
<ul>
<li>You will be a better programmer.</li>
<li>You can create tools for debugging and translating.</li>
<li>You can create new languages.</li>
<li>You can contribute to existing compilers.</li>
</ul>
<h2 id="what-language-should-i-use"><a class="header" href="#what-language-should-i-use">What language should I use</a></h2>
<ul>
<li>Author thinks you should use C and use it to compile a C like
language which produces assembly for a widely used processor like
x86 or ARM.</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="a-quick-tour"><a class="header" href="#a-quick-tour">A Quick Tour</a></h1>
<h2 id="the-compiler-toolchain"><a class="header" href="#the-compiler-toolchain">The Compiler Toolchain</a></h2>
<p><img src="./images/c2_compiler_toolchain.png" alt="" /></p>
<h2 id="stages-within-a-compiler"><a class="header" href="#stages-within-a-compiler">Stages Within a Compiler</a></h2>
<p><img src="./images/c2_compiler_stages.png" alt="" /></p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="scanning"><a class="header" href="#scanning">Scanning</a></h1>
<h2 id="kind-of-tokens"><a class="header" href="#kind-of-tokens">Kind of Tokens</a></h2>
<ul>
<li>Scanning is the process of identifying <strong>tokens</strong> from the raw text
source code of a program.</li>
</ul>
<p>Most languages will have tokens in these categories:</p>
<ul>
<li>Keywords</li>
<li>Identifiers</li>
<li>Numbers</li>
<li>Strings</li>
<li>Comments and Whitespace</li>
</ul>
<h2 id="a-hand-made-scanner"><a class="header" href="#a-hand-made-scanner">A Hand-Made Scanner</a></h2>
<ul>
<li>The basic approach is to read one character at a time from the input
stream (<code>fgetc(fp)</code>) and then classify it.</li>
<li>Hand Made scanner is usually verbose.</li>
<li>For a complex language with a large number of tokens, we need a more
formalized approach to defining and scanning tokens. A formal
approach will allow us to have a greater confidence that token
definitions do not conflict and the scanner is implemented
correctly.</li>
<li>The formal tools of <strong>regular expressions</strong> and <strong>finite automata</strong>
allow us to state very precisely what may appear in a given token
type. Then, automated tools can process these definitions, find
errors or ambiguities, and produce compact, high performance code.</li>
</ul>
<h2 id="regular-expressions"><a class="header" href="#regular-expressions">Regular Expressions</a></h2>
<ul>
<li>Regular expressions (REs) are a language for expressing patterns.</li>
<li>They were first described in the 1950s by Stephen Kleene.</li>
</ul>
<p><img src="./images/c3_regular_expression.png" alt="" /></p>
<p>Note that <em>ϵ</em> represents empty string.</p>
<p><img src="./images/c3_re_examples.png" alt="" /></p>
<p>The syntax described so far is entirely sufficient to write any regular
expression. But, it is also handy to have a few helper operations built
on top of the basic syntax:</p>
<p><img src="./images/c3_re_helpers.png" alt="" /></p>
<p>Regular expressions also obey several algebraic properties, which make
it possible to re-arrange them as needed for efficiency or clarity:</p>
<p><img src="./images/c3_re_algebric_properties.png" alt="" /></p>
<p>Some examples of regular expressions:</p>
<p><img src="./images/c3_re_more_examples.png" alt="" /></p>
<h2 id="finite-automata"><a class="header" href="#finite-automata">Finite Automata</a></h2>
<ul>
<li>A <strong>finite automaton (FA)</strong> is an abstract machine that can be used
to represent certain forms of computation.</li>
<li>Graphically, an FA consists of a number of states (represented by
numbered circles) and a number of edges (represented by labeled
arrows) between those states. Each edge is labeled with one or more
symbols drawn from an alphabet Σ.</li>
<li>The machine begins in a start state S0. For each input symbol
presented to the FA, it moves to the state indicated by the edge
with the same label as the input symbol.</li>
<li>Some states of the FA are known as <strong>accepting states</strong> and are
indicated by a double circle. If the FA is in an accepting state
after all input is consumed, then we say that the FA <strong>accepts</strong> the
input.</li>
<li>We say that the FA <strong>rejects</strong> the input string if it ends in a
non-accepting state, or if there is no edge corresponding to the
current input symbol.</li>
<li><strong>Every RE can be written as an FA, and vice versa.</strong></li>
<li>For a simple regular expression, one can construct an FA by hand.</li>
</ul>
<p>FA for regular expression <code>for</code>:</p>
<p><img src="./images/c3_fa_for.png" alt="" /></p>
<p>FA for regular expression <code>[a-z][a-z0-9]+</code>:</p>
<p><img src="./images/c3_fa_ex2.png" alt="" /></p>
<p>FA for regular expression <code>([1-9][0-9]*)|0</code></p>
<p><a href="./images/c3_fa_ex3.png"><img src="./images/c3_fa_ex3.png" alt="" /></a></p>
<h2 id="deterministic-finite-automata"><a class="header" href="#deterministic-finite-automata">Deterministic Finite Automata</a></h2>
<ul>
<li>Each of the above three examples is a <strong>deterministic finite
automaton (DFA)</strong>.</li>
<li>A DFA is a special case of an FA where every state has no more than
one outgoing edge for a given symbol.</li>
<li>Put another way, DFA has no ambiguity: For every combination of
state and symbol there is exactly one choice of what to do next.</li>
<li>DFA is easy to implement in software or hardware.</li>
</ul>
<h2 id="nondeterministic-finite-automata"><a class="header" href="#nondeterministic-finite-automata">Nondeterministic Finite Automata</a></h2>
<ul>
<li>The alternative to a DFA is a <strong>nondeterministic finite automaton
(NFA)</strong>. A NFA is a perfectly valid FA, but it has an ambiguity that
makes it somewhat more difficult to work with.</li>
<li>Example: Regular expression <code>[a-z]*ing</code> which represents all
lowercase ending in the suffix <code>ing</code>. It can be represented by the
following automaton:</li>
</ul>
<p><a href="./images/c3_nfa_ex1.png"><img src="./images/c3_nfa_ex1.png" alt="" /></a></p>
<p>There is a ambiguity in the above automamata because the word <code>sing</code>
could proceed in two different ways:</p>
<ul>
<li>State 0 (s) -&gt; State 1 (i) -&gt; State 2 (n) -&gt; Stage 3 (g)</li>
<li>State 0 (s) -&gt; State 0 (i) -&gt; State 0 (i) -&gt; State 0 (g)</li>
</ul>
<p>Both ways obey the transition rules, but one results in acceptance,
while the other results in rejection.</p>
<ul>
<li>And the above NFA becomes complicated for a word like <code>singing</code></li>
<li>An NFA can also have an <em>ϵ</em> (epsilon) transition, which represents
an empty string. This transition can be taken without consuming any
input symbols at all. For example, we could represent the regular
expression <code>a*(ab|ac)</code> with this NFA:</li>
</ul>
<p><a href="./images/c3_nfa_ex2.png"><img src="./images/c3_nfa_ex2.png" alt="" /></a></p>
<p>The above NFA also presents a variety of ambiguos choices:</p>
<ul>
<li>From state zero, it could consume <code>a</code> and stay in state zero.</li>
<li>From state zero, it could consume <em>ϵ</em> to state one.</li>
<li>From state zero, it could consume <em>ϵ</em> to state four.</li>
</ul>
<p>There are two common ways to interpret this ambiguity:</p>
<ul>
<li>The <strong>crystal ball interpretation</strong> says that NFA somehow knows what
the best choice is, by some means external to the NFA. Needless to
say, this isn't possible in a real implementation.</li>
<li>The <strong>many-worlds interpretation</strong> suggests that NFA exists in all
allowable states <code>simultaneously</code>. When the input is complete, if
any of those states are accepting states, then the NFA has accepted
the input. This interpretation is more useful for constructing a
working NFA, or converting it to a DFA.</li>
</ul>
<p>Let us use the many-worlds interpretation on the example above. Suppose
that the input string is <code>aaac</code>.</p>
<ul>
<li>Initial State: Initially the NFA is in state zero. Without consuming
any input, it could take an epsilon transition to states one or
four. So, we can consider it's initial state to be all of those
simultaneously.</li>
<li>Second State (after consuming <code>a</code>): From state zero, it can consume
<code>a</code> and remain in State 0, or go to state 1 or 4 with epsilon
transition. And from state one (from initial state on step 1), it
can go to state 2. Similarly from state 4 (from initial step on step
1), it can go to state 5. So in the second state, it can be in state
0, 1, 4, 2 or 5 simultaneously.</li>
</ul>
<p>NFA would traverse these states untill accepting the complete string
<code>aaac</code>:</p>
<p><a href="./images/c3_nfa_states.png"><img src="./images/c3_nfa_states.png" alt="" /></a></p>
<ul>
<li>In principal once can implement an NFA in software or hardware by
simply keeping track of all of the possible states. But it is
inefficient.</li>
<li>A better approach is to convert NFA into an equivalent DFA.</li>
</ul>
<h1 id="conversion-algorithms"><a class="header" href="#conversion-algorithms">Conversion Algorithms</a></h1>
<ul>
<li>For every RE, there is an FA, and vice versa.</li>
<li>DFA is by far the most straightfoward of the three to implement in
software.</li>
</ul>
<p><a href="./images/c3_relations.png"><img src="./images/c3_relations.png" alt="" /></a></p>
<h2 id="converting-res-to-nfas"><a class="header" href="#converting-res-to-nfas">Converting REs to NFAs</a></h2>
<ul>
<li>We follow the same inductive definition of regular expression as
given earlier. We define automata corresponding to base cases of
REs:</li>
</ul>
<p><a href="./images/c3_re_to_fa_1.png"><img src="./images/c3_re_to_fa_1.png" alt="" /></a></p>
<ul>
<li>If we write the concatenation of <code>A</code> and <code>B</code> as <code>AB</code>, then the
corresponding NFA is simply <code>A</code> and <code>B</code> connected by an <em>ϵ</em>
transition.</li>
</ul>
<p><a href="./images/c3_re_to_fa_2.png"><img src="./images/c3_re_to_fa_2.png" alt="" /></a></p>
<ul>
<li>In a similar fashion, the alternation of <code>A</code> and <code>B</code> written as
<code>A|B</code> can be expressed as two automata joined by common starting and
accepting nodes, all connected by <em>ϵ</em> transitions</li>
</ul>
<p><a href="./images/c3_re_to_fa_3.png"><img src="./images/c3_re_to_fa_3.png" alt="" /></a></p>
<ul>
<li>Finall, the Kleene closure <code>A*</code> is constructed by taking the
automaton for <code>A</code>, adding starting and accepting nodes, then adding
<em>ϵ</em> transitions to allow zero or more repetitions:</li>
</ul>
<p><a href="./images/c3_re_to_fa_4.png"><img src="./images/c3_re_to_fa_4.png" alt="" /></a></p>
<h3 id="example-convert-re-acatcow-to-nfa"><a class="header" href="#example-convert-re-acatcow-to-nfa">Example: Convert RE <code>a(cat|cow)*</code> to NFA</a></h3>
<ul>
<li>Step 1: Construct NFA for <code>cat</code> and <code>cow</code> (the innermost expression)</li>
</ul>
<p><a href="./images/c3_re_to_fa_eg1_s1.png"><img src="./images/c3_re_to_fa_eg1_s1.png" alt="" /></a></p>
<ul>
<li>Step 2: Construct NFA for <code>cat|cow</code></li>
</ul>
<p><a href="./images/c3_re_to_fa_eg1_s2.png"><img src="./images/c3_re_to_fa_eg1_s2.png" alt="" /></a></p>
<ul>
<li>Step 3: Construct NFA for Kleene closure <code>(cat|cow)*</code></li>
</ul>
<p><a href="./images/c3_re_to_fa_eg1_s3.png"><img src="./images/c3_re_to_fa_eg1_s3.png" alt="" /></a></p>
<ul>
<li>Step 4: Construct NFA for RE <code>a(cat|cow)*</code></li>
</ul>
<p><a href="./images/c3_re_to_fa_eg1_s4.png"><img src="./images/c3_re_to_fa_eg1_s4.png" alt="" /></a></p>
<p>Observations from the above example:</p>
<ul>
<li>It's complex and contains large number of epsilon transitions.</li>
<li>Could be impractical to implement for a complete language that could
end up having thousands of states.</li>
<li>Instead, we can convert NFA into an equivalent DFA.</li>
</ul>
<h2 id="converting-nfas-to-dfas"><a class="header" href="#converting-nfas-to-dfas">Converting NFAs to DFAs</a></h2>
<ul>
<li>The technique to convert any NFA into an equivalent DFA is called
<strong>subset construction</strong>.</li>
<li>Basic idea is to create a DFA such that each state in the DFA
corresponds to multiple states in the NFA, according to the
<code>many-worlds</code> interpretation.</li>
</ul>
<p><a href="./images/c3_epsilon_closure.png"><img src="./images/c3_epsilon_closure.png" alt="" /></a></p>
<p><a href="./images/c3_subet_algorithm.png"><img src="./images/c3_subet_algorithm.png" alt="" /></a></p>
<p>Example of converting NFA to DFA for the regualr expression which we saw
previously: <code>a(cat|cow)*</code></p>
<p><a href="./images/c3_nfa_to_dfa.png"><img src="./images/c3_nfa_to_dfa.png" alt="" /></a></p>
<p>Before diving into each steps, let's see a concrete example of epsilon
closure using the above example.</p>
<p><em>ϵ</em>-closure(<em>N</em><sub><em>o</em></sub>) = {<em>N</em><sub><em>o</em></sub>} because
<em>N</em><sub><em>o</em></sub> is the only state that is reachable from NFA state
<em>N</em><sub><em>o</em></sub> by zero or more <em>ϵ</em> transitions.</p>
<p>Each steps of the algorithm:</p>
<p><a href="./images/c3_nfa_to_dfa_step1.png"><img src="./images/c3_nfa_to_dfa_step1.png" alt="" /></a></p>
<p><a href="./images/c3_nfa_to_dfa_step2.png"><img src="./images/c3_nfa_to_dfa_step2.png" alt="" /></a></p>
<h2 id="minimizing-dfas"><a class="header" href="#minimizing-dfas">Minimizing DFAs</a></h2>
<ul>
<li>Large DFAs will consume a lot of memory.</li>
<li>We can apply Hopcroft's algorithm to shrink a DFA into a smaller
DFA.</li>
</ul>
<p><a href="./images/c3_minimization_algo.png"><img src="./images/c3_minimization_algo.png" alt="" /></a></p>
<p><a href="./images/c3_minimize_eg1_1.png"><img src="./images/c3_minimize_eg1_1.png" alt="" /></a></p>
<p>Observations:</p>
<ul>
<li>If we are in super-state (1,2,3,4) then an input of <code>a</code> always goes
to state 2, which keeps us within the super-state. So, this DFA is
consistent with respect to <code>a</code>.</li>
<li>From super-state (1,2,3,4) an input of <code>b</code> can either stay within
the super-state or go to super-state (5). So, the DFA is
inconsistent with respect to <code>b</code>.</li>
</ul>
<p><a href="./images/c3_minimize_eg1_2.png"><img src="./images/c3_minimize_eg1_2.png" alt="" /></a></p>
<p>Observations:</p>
<ul>
<li>We observe that super-state 1,2,3 is consistent with respect to <code>a</code>.</li>
<li>But not consistent with respect to <code>b</code> because it can either lead to
state 3 or state 4.</li>
<li>We attempt to fix this by splitting out state 2 into its own
super-state, yielding this DFA:</li>
</ul>
<p><a href="./images/c3_minimize_eg1_3.png"><img src="./images/c3_minimize_eg1_3.png" alt="" /></a></p>
<h1 id="limits-of-finite-automata"><a class="header" href="#limits-of-finite-automata">Limits of Finite Automata</a></h1>
<ul>
<li>Not sufficient to analyze all of the structures in a problem.</li>
<li>Designing a finite automaton to match an <strong>arbitrary</strong> number of
nested parenthesis is impractical.</li>
<li>So, we limit ourselves to using regular expressions and finite
automata for the narrow purpose of identifying the words and symbols
within a problem.</li>
</ul>
<h1 id="using-a-scanner-generator"><a class="header" href="#using-a-scanner-generator">Using a Scanner Generator</a></h1>
<ul>
<li>The program <strong>Lex</strong> developed at AT&amp;T was one of the earliest
examples of a scanner generator.</li>
<li>Vern Paxson translated Lex into the C language to create <strong>Flex</strong>.</li>
</ul>
<p><a href="./images/c3_flex_struct.png"><img src="./images/c3_flex_struct.png" alt="" /></a></p>
<p>To use Flex, we write a specification of the scanner that is a mixture
of regular expressions, fragments of C code, and some specialized
directives. The Flex program itself consumes the specification and
produces regular C code that can then be compiled in the normal way.</p>
<p>A peculiar requirement of Flex is that we must define a function
<code>yywrap()</code> which returns 1 to indicate that the input is complete at the
end of the file. If we wanted to continue scanning in another file, then
<code>yywrap()</code> would open the next file and return 0.</p>
<h2 id="syntax"><a class="header" href="#syntax">Syntax</a></h2>
<ul>
<li>The regular expression language accepted by Flex is very similar to
that of formal regular expressions discussed above.</li>
<li>The main difference is that characters that have special meaning
with a regular expression (like parentheses, square brackets, and
asterisks) must be escaped with a backslash or surrounded with
double quotes.</li>
<li>Also, a period (.) can be used to match any character at all, which
is helpful for catching error conditions.</li>
</ul>
<h2 id="other-details"><a class="header" href="#other-details">Other details</a></h2>
<ul>
<li>Flex generates the scanner code, but not a complete program, so you
must write a main function to go with it.</li>
<li>The main program must declar as
<a href="https://stackoverflow.com/questions/856636/effects-of-the-extern-keyword-on-c-functions"><strong>extern</strong></a>
the symbols it expects to use in the generated scanner code:
<ul>
<li><code>yyin</code> is the file from which text will be read</li>
<li><code>yylex</code> is the function that implements the scanner</li>
<li>array <code>yytext</code> contains the actual text of each token discovered</li>
</ul>
</li>
</ul>
<pre><code class="language-bash">flex -o scanner.c scanner.flex
</code></pre>
<h2 id="source-code"><a class="header" href="#source-code">Source code</a></h2>
<p>Filename: token.h</p>
<pre><code class="language-c">typedef enum {
  TOKEN_EOF=0,
  TOKEN_WHILE,
  TOKEN_ADD,
  TOKEN_IDENT,
  TOKEN_NUMBER,
  TOKEN_ERROR
} token_t;
</code></pre>
<p>Filename: scanner.flex</p>
<pre><code class="language-c">%{
#include &quot;token.h&quot;
%}
DIGIT  [0-9]
LETTER [a-zA-Z]
%%
(&quot; &quot;|\t|\n) /* skip whitespace */
\+        { return TOKEN_ADD; }
while     { return TOKEN_WHILE; }
{LETTER}+ { return TOKEN_IDENT; }
{DIGIT}+  { return TOKEN_NUMBER; }
.         { return TOKEN_ERROR; }
%%
int yywrap() { return 1; }
</code></pre>
<p>Filename: main.c</p>
<pre><code class="language-c">#include &quot;token.h&quot;
#include &lt;stdio.h&gt;

extern FILE *yyin;
extern int yylex();
extern char *yytext;

int main() {
  /* yyin = fopen(&quot;program.c&quot;,&quot;r&quot;); */
  FILE *yyin = stdin;
  if(!yyin) {
    printf(&quot;could not open program.c!\n&quot;);
    return 1;
  }
  while(1) {
    token_t t = yylex();
    if(t==TOKEN_EOF) break;
    printf(&quot;token: %d text: %s\n&quot;,t,yytext);
  }
}
</code></pre>
<p>Sample session:</p>
<pre><code class="language-bash">❯ ./one
hello world 32234
token: 3 text: hello
token: 3 text: world
token: 4 text: 32234
fooboar
token: 3 text: fooboar
   3
token: 4 text: 3
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="parsing"><a class="header" href="#parsing">Parsing</a></h1>
<h1 id="overview"><a class="header" href="#overview">Overview</a></h1>
<ul>
<li>To parse a computer program, we must first describe the form of
valid sentences in a language. This formal statement is known as a
context free grammar (CFG). Because they allow for recursion, CFGs
are more powerful than regular expressions and can express a richer
set of structures.</li>
<li>LL(1) grammars are CFGs that can be evaluated by considering only
the current rule and next token in the input stream. This property
makes it easy to write a hand-coded parser known as a recursive
descent parser.</li>
<li>LR(1) grammars are more general and more powerful than LL(1). Nearly
all useful programming languages can be written in LR(1) form.
However, the parsing algorithm for LR(1) grammars is more complex
and usually cannot be written by hand. Instead, it is common to use
a parser generator that will accept an LR(1) grammar and
automatically generate the parsing code.</li>
</ul>
<h1 id="context-free-grammars"><a class="header" href="#context-free-grammars">Context Free Grammars</a></h1>
<h2 id="terminal"><a class="header" href="#terminal">Terminal</a></h2>
<ul>
<li>A <strong>terminal</strong> is a discrete symbol that can appear in the language,
otherwise known as a <strong>token</strong> from the previous chapter.</li>
<li>Examples: keywords, operators and identifiers.</li>
<li>Convention: lower-case letters to represent terminals.</li>
</ul>
<h2 id="non-terminal"><a class="header" href="#non-terminal">Non terminal</a></h2>
<ul>
<li>A <strong>non-terminal</strong> represents a structure that can occur in a
language, but is not a literal symbol.</li>
<li>Examples: declarations, statements and expressions.</li>
<li>Convention: Upper-case letters to represent non terminals: <code>P</code> for
programs, <code>S</code> for statement, <code>E</code> for expression etc.</li>
</ul>
<h2 id="sentence"><a class="header" href="#sentence">Sentence</a></h2>
<ul>
<li>A <strong>sentence</strong> is a valid sequence of terminals in a language.</li>
</ul>
<h2 id="sentential-form"><a class="header" href="#sentential-form">Sentential form</a></h2>
<ul>
<li>A <strong>sentential form</strong> is a valid sequence of terminals and non
terminals.</li>
<li>Convention: Greek symbols to represent sentential forms. Example:
<em>α</em>, <em>β</em> and <em>γ</em> to represent possibly mixed sequence of terminals
and non-terminals. We will use a seqence like
<em>Y</em><sub>1</sub><em>Y</em><sub>2</sub>...<em>Y</em><sub><em>n</em></sub> to indicate the
individual symbols in a sentential form: <em>Y</em><sub><em>i</em></sub> may
either be a terminal or non terminal.</li>
</ul>
<h2 id="context-free-grammar-cfg"><a class="header" href="#context-free-grammar-cfg">Context Free Grammar (CFG)</a></h2>
<ul>
<li>A <strong>CFG</strong> is a list of <strong>rules</strong> that formally describe the
allowable sentences in a language.</li>
<li>The left hand side of each rule is always a single non-terminal.</li>
<li>The right hand side of a rule is a <strong>sentential form</strong> that
describes an allowable form of that non-terminal.</li>
<li>Example rule: <code>A -&gt; xXy</code> indicates that the non-terminal <code>A</code>
represents a terminal <code>x</code> followed by a non-terminal <code>X</code> and a
terminal <code>y</code>.</li>
<li>The right hand side of a rule can be <em>ϵ</em> to indicate that the rule
produces nothing.</li>
<li>The first rule is special: it is the top level definition of a
program and it's non terminal is known as the <strong>start symbol</strong></li>
</ul>
<p>Sample CFG describing expressions involving addition, integers and
identifiers:</p>
<p><a href="./images/c4_g2.png"><img src="./images/c4_g2.png" alt="" /></a></p>
<p>For brevity, the above grammar can also be written as:</p>
<p>E -&gt; E + E | ident | int</p>
<h2 id="deriving-sentences"><a class="header" href="#deriving-sentences">Deriving Sentences</a></h2>
<ul>
<li>Each grammar describes a (possibly infinite) set of sentences, which
is known as the <strong>language</strong> of the grammar.</li>
<li>To prove that a given sentence is a member of that language, we must
show that there exists a sequence of rule applications that connects
the start symbol with the desired sentence.</li>
<li>A sequence of rule applications is known as a <strong>derivation</strong> and a
double arrow (⇒) is used to show that one sentential form is equal
to another by applying a given rule. Example: E ⇒ int by applying
rule 4 of grammer G2.</li>
</ul>
<p>There are two approaches to derivation:</p>
<ul>
<li>top-down: Begin with the start symbol, and then apply rules in the
CFG to expand non terminals until reaching the desired sentence.</li>
<li>bottom-up: Begin with the desired setence, and then apply the rules
backwards until reaching the start symbol.</li>
</ul>
<p>For example, <code>ident + int + int</code> is a sentence in this language and here
is one top-down derivation to prove it:</p>
<p><a href="./images/c4_g2_top_down.png"><img src="./images/c4_g2_top_down.png" alt="" /></a></p>
<p>And similar proof using bottom-up derivation:</p>
<p><img src="./images/c4_g2_bottom_up.png" alt="" /></p>
<p>It is quite possible for two different grammars to generate the same
language, in which case we describe them as having <strong>weak equivalence</strong>.</p>
<h2 id="ambiguous-grammars"><a class="header" href="#ambiguous-grammars">Ambiguous Grammars</a></h2>
<ul>
<li>An <strong>ambiguous grammar</strong> allows for more than one possible
derivation of the same sentence.</li>
<li>Example: The sentence <code>ident + int + int</code> can have two derivations:</li>
</ul>
<p><img src="./images/c4_ambigous_grammar.png" alt="" /></p>
<ul>
<li>Does it matter in the above case ? It certainly does!</li>
<li>In a language like Java such a sentence <code>hello + 5 + 5</code> could be
interpreted as either <code>hello55</code> or <code>hello10</code> and that's not good.</li>
<li>It is possible to re-write a grammer so that it is not ambiguous. In
the common case of binary operators, we can require that one side of
the expression be an atomic term (T), like this:</li>
</ul>
<p><a href="./images/c4_g3.png"><img src="./images/c4_g3.png" alt="" /></a></p>
<ul>
<li>With this change, the grammer is no longer ambigous. But it still
accepts the same language as Grammer <em>G</em><sub>2</sub></li>
<li>If you want to construct a grammar with more operators (division,
muliplication) - then the usual approach is to construct a grammar
with multiple levels that reflect the intended precedence of
operators:</li>
</ul>
<p><a href="./images/c4_g4.png"><img src="./images/c4_g4.png" alt="" /></a></p>
<p>Grammar which supports two if statements (if-then and if-then-else
variant):</p>
<p><a href="./images/c4_g5.png"><img src="./images/c4_g5.png" alt="" /></a></p>
<p>The above grammer is ambiguous because it allows for two derivations of
this sentence:</p>
<ul>
<li>If E then if E then other else other</li>
</ul>
<p>There are two derivations of this sentence:</p>
<ul>
<li>If E then (if E then other else other)</li>
<li>If E then (if E then other) else other</li>
</ul>
<h1 id="ll-grammars"><a class="header" href="#ll-grammars">LL Grammars</a></h1>
<ul>
<li>LL(1) grammars are a subset of CFGs that are easy to parse with
simple algorithms.</li>
<li>A grammar is LL(1) if it can be parsed by considering only one
non-terminal and the next token in the input stream.</li>
</ul>
<p>To ensure a grammar is LL(1) we must do the following:</p>
<ul>
<li>Remove any ambiguity as shown above.</li>
<li>Eliminate any left recursion.</li>
<li>Eliminate any common left prefixes.</li>
</ul>
<h2 id="eliminating-left-recursion"><a class="header" href="#eliminating-left-recursion">Eliminating Left recursion</a></h2>
<p>LL(1) grammars cannot contain <strong>left recursion</strong> which is a rule of the
form A → A<em>α</em> or, more generally, any rule A → B<em>β</em> such that B ⇒ A<em>γ</em>
by some sequence of derivations.</p>
<p><a href="./images/c4_elim_left_recur.png"><img src="./images/c4_elim_left_recur.png" alt="" /></a></p>
<h2 id="eliminating-common-left-prefixes"><a class="header" href="#eliminating-common-left-prefixes">Eliminating Common Left Prefixes</a></h2>
<p><a href="./images/c4_elim_comm_prefix_1.png"><img src="./images/c4_elim_comm_prefix_1.png" alt="" /></a></p>
<p>Fixing the grammar will result in:</p>
<p><a href="./images/c4_g8.png"><img src="./images/c4_g8.png" alt="" /></a></p>
<h2 id="first-and-follow-sets"><a class="header" href="#first-and-follow-sets">First and Follow Sets</a></h2>
<ul>
<li>In order to construct a complete parser for an LL(1) grammar, we
must compute two sets, known as <code>FIRST</code> and <code>FOLLOW</code>.</li>
<li>Informally, FIRST(<em>α</em>) indicates the set of terminals (including
<em>ϵ</em>) that could potentially appear at the beginning of any
<strong>derivation</strong> of <em>α</em>.</li>
<li>FOLLOW(A) indicates the set of terminals (including $) that could
potentially occur after any derivation of non-terminal A.</li>
<li>Given the contents of these two set, the LL(1) parser will always
know <code>which rule to pick next</code>.</li>
</ul>
<p><a href="./images/c4_first_set.png"><img src="./images/c4_first_set.png" alt="" /></a></p>
<p><em>Y</em><sub>1</sub>...<em>Y</em><sub><em>n</em> − 1</sub> ⇒ <em>ϵ</em> means
<em>ϵ</em> ∈ FIRST(<em>Y</em><sub>1</sub>)...<em>ϵ</em> ∈ FIRST(<em>Y</em><sub><em>n</em> − 1</sub>)</p>
<p><a href="./images/c4_follow_sets.png"><img src="./images/c4_follow_sets.png" alt="" /></a></p>
<p>I also found the following source very helpful:</p>
<ul>
<li><a href="https://www.jambe.co.nz/UNI/FirstAndFollowSets.html">jambe.con.nz
source</a> (For
first sets)</li>
<li><a href="http://www.cs.ecu.edu/karl/5220/spr16/Notes/Top-down/follow.html">cs.ecu.edu
source</a>
<a href="https://web.archive.org/web/20190203020902/http://www.cs.ecu.edu/karl/5220/spr16/Notes/Top-down/follow.html">Archive
link</a>
(For follow set, example specifically)</li>
</ul>
<p>I personally found that working out the examples, let me to understand
the above algorithm better. Always going back to the informal definition
above will help you. Now let's see an example:</p>
<p><a href="./images/c4_g9.png"><img src="./images/c4_g9.png" alt="" /></a></p>
<p>You can also use this <a href="https://hackage.haskell.org/package/context-free-grammar-0.1.1/docs/Data-Cfg-Analysis.html">Haskell
module</a>
to find them. (Future todo: Write a blog post about it)</p>
<p>Let's find out the First sets initially. Let's try to find out
<strong>FIRST(P)</strong>. Going back to the formal definition:</p>
<p><strong>FIRST(P)</strong> is the set of terminals that being all strings given by
<strong>P</strong>. Looking at the grammar, it is hard to come up for non terminal
**P* since it depens on other non terminals. Let's try to move from
*the non terminals at the end of the grammar:</p>
<ul>
<li>FIRST(F) = {(, int}</li>
<li>FIRST(T') = {*, ϵ }</li>
<li>FIRST(T) = {(, int } (Same as the first set of F)</li>
<li>FIRST(E') = {ϵ, +}</li>
<li>FIRST(E) = {(, int } (Same as the first set of T)</li>
<li>FIRST(P) = {(, int } (Same as the first set of E)</li>
</ul>
<p>Now let's find out the Follow sets. Let's try to find out <strong>FOLLOW(P)</strong>.
Going back to the formal definition:</p>
<p><strong>FOLLOW(P)</strong> is the set of terminal that can come after non-terminal
<strong>P</strong>, including $ if P occurs at the end of input.</p>
<ul>
<li>FOLLOW(P) = {$} (P represents the program and it includes $ since P
occurs at the end of input).</li>
<li>FOLLOW(E) = {),$} (For $, same logic as above)</li>
<li>FOLLOW(E') = {),$} (F =&gt; (E) =&gt; (TE'), so it includes <strong>)</strong>)</li>
<li>FOLLOW(T) = {),$, +}
<ul>
<li>Same as FOLLOW(E') since E -&gt; TE'</li>
<li>Also includes <code>+</code> since E =&gt; TE' =&gt; T+TE'</li>
</ul>
</li>
<li>FOLLOW(T') = {),$, +}
<ul>
<li>E =&gt; TE' =&gt; FT'E'. So same as FOLLOW(E')</li>
<li>FT'E' =&gt; FT'+TE', so includes +</li>
</ul>
</li>
<li>FOLLOW(F) = {),$,+,*}
<ul>
<li>Same as FOLLOW(T') since T =&gt; FT'</li>
<li>Also includes <code>*</code> since FT' =&gt; F*FT'</li>
</ul>
</li>
</ul>
<h2 id="recursive-descent-parsing"><a class="header" href="#recursive-descent-parsing">Recursive Descent Parsing</a></h2>
<ul>
<li>LL(1) grammars are very amenable to write simple hand-coded parsers.</li>
<li>A common approach is a <strong>recursive descent parser</strong> in which there
is one simple function for each non-terminal in the grammar. The
body of the function follow the right hand sides of the
corresponding rules: non-terminal results in a call to another parse
function, while terminals result in considering the next token.</li>
</ul>
<h2 id="table-driven-parsing"><a class="header" href="#table-driven-parsing">Table Driven Parsing</a></h2>
<ul>
<li>An LL(1) grammar can also be parsed using generalized table driven
code.</li>
<li>A table driven parser requires a grammar, a parse table and a stack
to represent the current set of non-terminals.</li>
<li>The <strong>LL(1) parse table</strong> is used to determine which rule should be
applied for any combination of non-terminal on the stack and next
token on the input stream.</li>
</ul>
<p><a href="./images/c4_l1_parse_table.png"><img src="./images/c4_l1_parse_table.png" alt="" /></a></p>
<p><a href="./images/c4_parse_table_g9.png"><img src="./images/c4_parse_table_g9.png" alt="" /></a></p>
<p><a href="./images/c4_ll_parsing_algo.png"><img src="./images/c4_ll_parsing_algo.png" alt="" /></a></p>
<h1 id="lr-grammars"><a class="header" href="#lr-grammars">LR Grammars</a></h1>
<ul>
<li>While LL(1) grammars and top-down parsing techniques are easy to
work with, they are not able to represent all of the structures
found in many programming languages. For more general-purpose
programming languages, we must use an LR(1) grammar and associated
bottom-up parsing techniques.</li>
<li>LR(1) is the set of grammars that can be parsed via shift-reduce
techniques with a single character of lookahead.</li>
<li>LR(1) is a super-set of LL(1) and can accommodate left recursion and
common left prefixes which are not permitted in LL(1).</li>
</ul>
<p>Example of LR(1) grammar:</p>
<p><a href="./images/c4_g10.png"><img src="./images/c4_g10.png" alt="" /></a></p>
<p>And it's first and follow sets are these:</p>
<p><a href="./images/c4_g10_sets2.png"><img src="./images/c4_g10_sets2.png" alt="" /></a></p>
<h2 id="shift-reduce-parsing"><a class="header" href="#shift-reduce-parsing">Shift Reduce Parsing</a></h2>
<ul>
<li>LR(1) grammars must be parsed using the <strong>shift-reduce</strong> parsing
technique. This is a bottom-up parsing strategy that begins with the
tokens and looks for rules that can be applied to reduce sentential
forms into non-terminals. If there is a sequence of reductions that
leads to the start symbol, then the parse is successful.</li>
<li>A <strong>shift</strong> action consumes one token from the input stream and
pushes it onto the stack.</li>
<li>A <strong>reduce</strong> action applies one rule of the form <em>A</em> → <em>α</em> from the
grammar, replacing sentential form <em>α</em> on the stack with the non
terminal <em>A</em>.</li>
</ul>
<p>Example of shift-reduce parse of the sentence <code>id(id+id)</code> using Grammar
<em>G</em><sub>10</sub>:</p>
<p><a href="./images/c4_shift_reduce.png"><img src="./images/c4_shift_reduce.png" alt="" /></a></p>
<p>In the above example, you can see that there is some action chosen at
each step. To understand how these decisions are made, we must analyze
LR(1) grammars in more detail.</p>
<h2 id="the-lr0-automaton"><a class="header" href="#the-lr0-automaton">The LR(0) Automaton</a></h2>
<ul>
<li>An <strong>LR(0) automaton</strong> represents all the possible rules that are
currently under consideration by a shift-reduce parser.</li>
<li>Each state in the automaton consists of multiple <strong>items</strong>, which
are rules augmented by a <strong>dot(.)</strong> that indicates the parser's
current position in that rule. For example, the configuration
<em>E</em> → <em>E</em>. + <em>T</em> indicates that <em>E</em> is currently on the stack, and
 + <em>T</em> is a possible next sequence of tokens.</li>
<li>The automaton is constructed as follows. State 0 is created by
taking the production for the start symbol (<em>P</em>→<em>E</em>) and adding a
dot at the beginning of the right hand. This indicates that we
expect to see a complete program, but have not yet consumed any
symbols. This is known as the <strong>kernel</strong> of the state.</li>
</ul>
<p><img src="./images/c4_kernel.png" alt="" /></p>
<ul>
<li>Then, we compute the <strong>closure</strong> of the state as follows. For each
item in the state with a non-terminal <em>X</em> immediately to the right
of the dot, we add all the grammar that have X as the left hand
side. The newly added items have a dot at the beginning of the right
hand side.</li>
</ul>
<p><img src="./images/c4_closure.png" alt="" /></p>
<ul>
<li>From this state, all of the symbols (terminals and non-terminals
both) to the right of the dot are possible outgoing transitions. If
the automaton takes that transition, it moves to a new state
containing the matching items, with the dot moved one position to
the right. The closure of the new state is computed, possibly adding
new rules as described above.</li>
</ul>
<p><img src="./images/c4_transition.png" alt="" /></p>
<p><a href="./images/c4_lr_automaton.png"><img src="./images/c4_lr_automaton.png" alt="" /></a></p>
<ul>
<li>The LR(0) automaton tells us the choices available at any step of
bottom up parsing. When we reach a state containing an item with a
dot at the end of the rule, that indicates a possible reduction. A
transition on a terminal that moves the dot one position to the
right indicates a possible shift. While the LR(0) automaton tells us
the available actions at each step, it does not always tell us
<code>which</code> action to take.</li>
</ul>
<p>Two types of conflict can appear in an LR grammar:</p>
<ul>
<li>A <strong>shift-reduce conflict</strong> indicates a choice between a shift
action and a reduce action. Example: State 4 in the above automaton</li>
</ul>
<p><a href="./images/c4_shift_reduce_conflict.png"><img src="./images/c4_shift_reduce_conflict.png" alt="" /></a></p>
<ul>
<li>A <strong>reduce-reduce conflict</strong> indicates that two distinct rules have
been completely matched, and either one could apply.</li>
</ul>
<p><a href="./images/c4_reduce_reduce.png"><img src="./images/c4_reduce_reduce.png" alt="" /></a></p>
<p>The LR(0) automaton forms the basis of LR parsing, by telling us which
actions are available in each state. But, it does not tell us which
action to take or how to resolve shift-reduce and reduce-reduce
conflicts. To do that, we must take into account some additional
information.</p>
<h2 id="slr-parsing"><a class="header" href="#slr-parsing">SLR Parsing</a></h2>
<ul>
<li><strong>Simple LR(SLR)</strong> parsing is basic form of LR parsing in which we
use <code>FOLLOW</code> sets to resolve conflicts in the <code>LR(0)</code> automaton.</li>
<li>In short, we take the reduction <em>A</em> → <em>α</em> only when the next token
on the input is in <code>FOLLOW(A)</code>. If a grammar can be parsed by this
technique, we say it is an <strong>SLR grammar</strong>, which is a subset of
LR(1) grammars.</li>
<li>Taking the example in the above automaton for State 4, there are two
possible cases:
<ul>
<li>If the next token is <code>(</code>, then we shift to state 5.</li>
<li>If the next token is <code>+,)</code> or <code>$</code>, then we reduce by the rule <code>T -&gt; id</code>.</li>
</ul>
</li>
<li>These decisions are encoded in <strong>SLR parse tables</strong> which are
historically known as <strong>GOTO</strong> and <strong>ACTION</strong>.</li>
</ul>
<p><a href="./images/c4_slr_parse_table_creation.png"><img src="./images/c4_slr_parse_table_creation.png" alt="" /></a></p>
<p>Let's follow the above algorithm to construct SLR parse table ourselves
for grammar <em>G</em><sub>10</sub>. Some conventions to keep in mind:</p>
<ul>
<li>Rn: n represents the Rule number (to which it has to reduce to).</li>
<li>Sn: n represents the state number (to which it has to shift to).</li>
<li>Gn: n represents the state number (to which it has to goto).</li>
</ul>
<p>The easy way to compute is to look at the LR(0) Automaton for the
grammar.</p>
<h3 id="state-0"><a class="header" href="#state-0">State 0</a></h3>
<p>The core idea of the above algorithm is that you create the <strong>ACTION</strong>
table for the terminals and the <strong>GOTO</strong> table for non terminals. Using
that let's construct the table for state zero:</p>
<ul>
<li>A[0, id] = S4</li>
<li>G[0, E] = G1</li>
<li>G[0, T] = G8</li>
</ul>
<h3 id="state-1"><a class="header" href="#state-1">State 1</a></h3>
<ul>
<li>Follow(P) = $</li>
<li>A[1, +] = S2</li>
<li>A[0, $] = R1</li>
</ul>
<h3 id="state-2"><a class="header" href="#state-2">State 2</a></h3>
<ul>
<li>G[2, T] = G3</li>
<li>A[2, id] = S4</li>
</ul>
<h3 id="state-3"><a class="header" href="#state-3">State 3</a></h3>
<ul>
<li>Follow(E) = {$, ), +}</li>
<li>A[3, $] = R2</li>
<li>A[3, )] = R2</li>
<li>A[3, +] = R2</li>
</ul>
<h3 id="state-4"><a class="header" href="#state-4">State 4</a></h3>
<ul>
<li>Follow(T) = {$, ), +}</li>
<li>A[4, (] = S5</li>
<li>A[4, $] = R5</li>
<li>A[4, )] = R5</li>
<li>A[4, +] = R5</li>
</ul>
<h3 id="state-5"><a class="header" href="#state-5">State 5</a></h3>
<ul>
<li>A[5, id] = S4</li>
<li>G[5, E] = G6</li>
<li>G[5, T] = G8</li>
</ul>
<h3 id="state-6"><a class="header" href="#state-6">State 6</a></h3>
<ul>
<li>A[6, +] = S2</li>
<li>A[6, )] = S7</li>
</ul>
<h3 id="state-7"><a class="header" href="#state-7">State 7</a></h3>
<ul>
<li>Follow(T) = {$, ), +}</li>
<li>A[7, $] = R4</li>
<li>A[7, )] = R4</li>
<li>A[7, +] = R4</li>
</ul>
<h3 id="state-8"><a class="header" href="#state-8">State 8</a></h3>
<ul>
<li>Follow(E) = {$, ), +}</li>
<li>A[8, $] = R3</li>
<li>A[8, +] = R3</li>
<li>A[8, )] = R3</li>
</ul>
<p>And that corresponds with the SLR parse table given in the book:</p>
<p><a href="./images/c4_slr_parse_table.png"><img src="./images/c4_slr_parse_table.png" alt="" /></a></p>
<p><a href="./images/c4_slr_parse_algorithm.png"><img src="./images/c4_slr_parse_algorithm.png" alt="" /></a></p>
<p><a href="./images/c4_slr_parse.png"><img src="./images/c4_slr_parse.png" alt="" /></a></p>
<p>Let's try to follow the first four steps of the above algorithm:</p>
<h3 id="step-1"><a class="header" href="#step-1">Step 1</a></h3>
<ul>
<li>Stack: 0</li>
<li>Top of Stack: 0</li>
<li>Token: id</li>
<li>SLR parse table result = S4</li>
</ul>
<h3 id="step-2"><a class="header" href="#step-2">Step 2</a></h3>
<ul>
<li>Stack: 0 4</li>
<li>Top of Stack: 4</li>
<li>Token: (</li>
<li>SLR parse table result = S5</li>
</ul>
<h3 id="step-2-1"><a class="header" href="#step-2-1">Step 2</a></h3>
<ul>
<li>Stack: 0 4 5</li>
<li>Top of Stack 5</li>
<li>Token: id</li>
<li>SLR parse table result = S4</li>
</ul>
<h3 id="step-3"><a class="header" href="#step-3">Step 3</a></h3>
<ul>
<li>Stack: 0 4 5 4</li>
<li>Top of Stack 4</li>
<li>Token: +</li>
<li>SLR parse table result = R5
<ul>
<li>It's reduce (T-&gt;id), pop state from stack.</li>
<li>s = top element from stack</li>
<li>Goto[5, T] = G8</li>
<li>New stack: 0 4 5 8</li>
</ul>
</li>
</ul>
<h2 id="limitation"><a class="header" href="#limitation">Limitation</a></h2>
<ul>
<li>SLR is a subset of LR(1), and not all LR(1) grammars are SLR.</li>
</ul>
<p><a href="./images/c4_g11.png"><img src="./images/c4_g11.png" alt="" /></a></p>
<ul>
<li>FOLLOW(S) = {$} and FOLLOW(V) = {=]$}</li>
<li>In state 1, we can reduce by S -&gt; id or V -&gt; id. However, both
FOLLOW(S) and FOLLOW(V ) contain $, so we cannot decide which to
take when the next token is end-of-file. Even using the FOLLOW sets,
there is still a reduce-reduce conflict. Therefore, Grammar G11 is
not an SLR grammar</li>
<li>But, if we look more closely at the possible sentences allowed by
the grammar, the distinction between the two becomes clear. Rule <code>S -&gt; id</code> would only be applied in the case where the complete
sentence is <code>id$</code>. If any other character follows, we apply
<code>V -&gt; id</code>. So the grammar is not ambigous, we need a more powerful
parser.</li>
</ul>
<h1 id="lr1-parsing"><a class="header" href="#lr1-parsing">LR(1) Parsing</a></h1>
<ul>
<li>The LR(1) automaton is like the LR(0) automaton, except that each
item is annotated with the set of tokens that could potentially
follow it, given the current parsing state.</li>
<li>This set is known as the lookahead of the item. The lookahead is
always a subset of the FOLLOW of the relevant non-terminal.</li>
</ul>
<p><a href="./images/c4_lr1.png"><img src="./images/c4_lr1.png" alt="" /></a></p>
<p><a href="./images/c4_lr1_2.png"><img src="./images/c4_lr1_2.png" alt="" /></a></p>
<ul>
<li>Now you can see how the lookahead solves the reduce-reduce conflict.</li>
</ul>
<p><a href="./images/c4_lr1_automaton.png"><img src="./images/c4_lr1_automaton.png" alt="" /></a></p>
<p>One aspect of state zero is worth clarifying. When constructing the
closure of a state, we must consider all rules in the grammar, including
the rule corresponding to the item under closure. The item E -&gt; .E + T
is initially added with a lookahead of {$}. Then, evaluating that item,
we add all rules that have E on the left hand side, adding a lookahead
of {<s>}. So, we add E -&gt; . E + T again, this time with a lookahead of
{</s>}, resulting in a single item with a lookahead set of {$, +}</p>
<h1 id="lalr-parsing"><a class="header" href="#lalr-parsing">LALR Parsing</a></h1>
<ul>
<li>The main downside to LR(1) parsing is that the LR(1) automaton can
be much larger than the LR(0) automaton.</li>
<li>Any two states that have the same items but differ in lookahead sets
for any items are considered to be different states. The result is
enormous parse tables that consume large amounts of memory and slow
down the parsing algorithm.</li>
<li><strong>Lookahead LR (LALR)</strong> parsing is the practical answer to this
problem.</li>
<li>To construct an LALR parser, we first create the LR(1) automaton,
and then merge states that have the same core. The core of a state
is simply the body of an item, ignoring the lookahead.</li>
<li>When several LR(1) items are merged into one LALR item, the LALR
lookahead is the union of the lookaheads of the LR(1) items.</li>
</ul>
<p><a href="./images/c4_lalr.png"><img src="./images/c4_lalr.png" alt="" /></a></p>
<ul>
<li>The resulting LALR automaton has the same number of states as the
LR(0) automaton, but has more precise lookahead information
available for each item.</li>
</ul>
<h1 id="grammar-classes-revisited"><a class="header" href="#grammar-classes-revisited">Grammar Classes Revisited</a></h1>
<p><a href="./images/c4_grammars.png"><img src="./images/c4_grammars.png" alt="" /></a></p>
<h2 id="cfg"><a class="header" href="#cfg">CFG</a></h2>
<ul>
<li>A context-free grammar is any grammar whose rules have the form A →</li>
</ul>
<p>α.</p>
<ul>
<li>To parse any CFG, we require a finite automaton (a parse table) and</li>
</ul>
<p>a stack to keep track of the parse state.</p>
<ul>
<li>An arbitrary CFG can be ambiguous. An ambiguous CFG will result in a
non-deterministic finite automaton, which is not practical to use.</li>
</ul>
<h2 id="lrk"><a class="header" href="#lrk">LR(k)</a></h2>
<ul>
<li>An LR(k) parser performs a bottom-up *L*eft to right scan of the
input and provides a *R*ight-most parse, deciding what rule to
apply next by examining the next <code>k</code> tokens on the input.</li>
<li>A canonical LR(1) parser requires a very large finite automaton,
because the possible lookaheads are encoded into the states.</li>
<li>While strictly a subset of CFGs, nearly all realworld language
constructs can be expressed adequately in LR(1).</li>
</ul>
<h2 id="lalr"><a class="header" href="#lalr">LALR</a></h2>
<ul>
<li>A Lookahead-LR parser is created by first constructing a canonical
LR(1) parser, and then merging all itemsets that have the same core.</li>
<li>This yields a much smaller finite automaton, while retaining some
detailed lookahead information.</li>
<li>While less powerful than canonical LR(1) in theory, LALR is usually
sufficient to express real-world languages.</li>
</ul>
<h2 id="slr"><a class="header" href="#slr">SLR</a></h2>
<ul>
<li>A Simple-LR parser approximates an LR(1) parser by constructing the
LR(0) state machine, and then relying on the FIRST and FOLLOW sets
to select which rule to apply.</li>
<li>SLR is simple and compact, but there are easy-to-find examples of
common constructs that it cannot parse.</li>
</ul>
<h2 id="llk"><a class="header" href="#llk">LL(k)</a></h2>
<ul>
<li>An LL(k) parser performs a top-down *L*eft to right scan of the
input and provides a *L*eft-most parse, deciding what rule to
apply next by examining the next <code>k</code> tokens on the input.</li>
<li>LL(1) parsers are simple and widely used because they require a
table that is only O(nt) where t is the number of tokens, and n is
the number of non-terminals</li>
<li>LL(k) parsers are less practical for k &gt; 1 because the size of the
parse table is O(n (t<sup>k</sup>) ) in the worst case.</li>
<li>They often require that a grammar be rewritten to be more amenable
to the parser, and are not able to express all common language
structures.</li>
</ul>
<h1 id="the-chomsky-hierarchy"><a class="header" href="#the-chomsky-hierarchy">The Chomsky Hierarchy</a></h1>
<ul>
<li>Named after noted linguist Noam Chomsky.</li>
<li>The hierarchy describes four categories of languages (and
corresponding grammars) and relates them to the abstract computing
machinery necessary to recognize such a language.</li>
</ul>
<p><a href="./images/c4_chomsky.png"><img src="./images/c4_chomsky.png" alt="" /></a></p>
<h2 id="regular-languages"><a class="header" href="#regular-languages">Regular Languages</a></h2>
<ul>
<li>Regular languages are those described by regular expressions.</li>
<li>Every regular expression corresponds to a finite automaton that can
be used to identify all words in the corresponding language.</li>
<li>As you know, a finite automaton can be implemented with the very
simple mechanism of a table and a single integer to represent the
current state. So, a scanner for a regular language is very easy to
implement efficiently.</li>
</ul>
<h2 id="context-free-languages"><a class="header" href="#context-free-languages">Context Free languages</a></h2>
<ul>
<li>Context free languages are those described by context free grammars
where each rule is of the form A → γ, with a single non-terminal on
the left hand side, and a mix of terminals and non-terminals on the
right hand side.</li>
<li>We call these “context free” because the meaning of a non-terminal
is the same in all places where it appears.</li>
<li>As you have learned in this chapter, a CFG requires a pushdown
automaton, which is achieved by coupling a finite automaton with a
stack.</li>
</ul>
<h2 id="context-sensitive-languages"><a class="header" href="#context-sensitive-languages">Context sensitive languages</a></h2>
<ul>
<li>Context sensitive languages are those described by context sensitive
grammars where each rule can be of the form αAβ → αγβ.</li>
<li>We call these “context sensitive” because the interpretation of a
non-terminal is controlled by context in which it appears.</li>
<li>Context sensitive languages require a non-deterministic linear
bounded automaton, which is bounded in memory consumption, but not
in execution time.</li>
<li>Context sensitive languages are not very practical for computer
languages.</li>
</ul>
<h2 id="recursively-enumerable-languages"><a class="header" href="#recursively-enumerable-languages">Recursively enumerable languages</a></h2>
<ul>
<li>Are the least restrictive set of languages, described by rules of
the form α → β where α and β can be any combination of terminals and
non-terminals.</li>
<li>These languages can only be recognized by a full Turing machine, and
are the least practical of all.</li>
</ul>
<p>The Chomsky Hierarchy is a specific example of a more general principle
for the design of languages and compilers:</p>
<p><strong>The least powerful language gives the strongest guarantees.</strong></p>
<p>That is to say, if we have a problem to be solved, it should be attacked
using the least expressive tool that is capable of addressing the
problem. If we can solve a given problem by employing REs instead of
CFGs, then we should use REs, because they consume less state, have
simpler machinery, and present fewer roadblocks to a solution.</p>
<p>The same advice applies more broadly: assembly language is the most
powerful language available in our toolbox and is capable of expressing
any program that the computer is capable of executing. However, assembly
language is also the most difficult to use because it gives none of the
guarantees found in higher level languages. Higher level languages are
less powerful than assembly language, and this is what makes them more
predictable, reliable, and congenial to use.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="parsing-in-practice"><a class="header" href="#parsing-in-practice">Parsing in Practice</a></h1>
<ul>
<li>While LL(1) parsers are commonly written by hand, LR(1) parsers are
simply too cumbersome to do the same.</li>
<li>Instead, we rely upon a <strong>parser generator</strong> to take a specification
of a grammar and automatically produce the working code.</li>
<li>In this chapter, we will look into <strong>Bison</strong>.</li>
</ul>
<p>Using Bison, we will define an LALR grammar for algebraic expressions,
and then employ it to create three different varieties of programs:</p>
<ul>
<li>A <strong>validator</strong> reads the input program and then simply informs the
user whether it is a valid sentence in the language specified by the
grammar.</li>
<li>An <strong>interpreter</strong> reads the input program and then actually
executes the program to produce a result.</li>
<li>A <strong>translator</strong> reads the input program, parses it into an abstract
syntax tree, and then traverses the abstract syntax tree to produce
an equivalent program in a different format.</li>
</ul>
<h1 id="the-bison-parser-generator"><a class="header" href="#the-bison-parser-generator">The Bison Parser Generator</a></h1>
<ul>
<li>It is not practical to implement an LALR parser by hand, and so we
rely on tools to automatically generate tables and code from a
grammar specification.</li>
<li>YACC (Yet Another Compiler Compiler) was a widely used parser
generator in the Unix environment, recently supplanted by the GNU
Bison parser which is generally compatible.</li>
<li>Bison is designed to automatically invoke Flex as needed, so it is
easy to combine the two into a complete program.</li>
</ul>
<p>The overall structure of a Bison file is similar to that of Flex:</p>
<pre><code class="language-bison">%{
   (C PREAMBLE CODE)
%}
   (declarations)
%%
   (grammar rules)
%%
   (C postamble code)
</code></pre>
<ul>
<li>The second section can contain a variety of declarations specific to
the Bison language. We will use the <code>%token</code> keyword to declare all
of the terminals in our language.</li>
</ul>
<p>The main body of the file contains a series of rules of the form:</p>
<pre><code class="language-bison">expr : expr TOKEN_ADD expr
     | TOKEN_INT
     ;
</code></pre>
<ul>
<li>The above code indicats that the non terminal <code>expr</code> can produce the
sentence <code>expr TOKEN_ADD expr</code> or single terminal <code>TOKEN_INT</code>.</li>
<li>White space is not significant, so it’s ok to arrange the rules for
clarity.</li>
<li>Note that the usual naming convention is reversed: since upper case
is customarily used for C constants, we use lower case to indicate
non-terminals.</li>
<li>The resulting code creates a single function <code>yyparse()</code> than
returns an integer:
<ul>
<li>zero indicates a successful parse</li>
<li>one indicates a parse error</li>
<li>two indicates an internal problem such as memory exhaustion</li>
</ul>
</li>
<li><code>yyparse</code> assumes that there exists a function <code>yylex</code> that returns
integer token types. This can be written by hand or generated
automatically by Flex.</li>
</ul>
<pre><code class="language-bash">bison --defines=token.h --output=parser.c parser.bison
</code></pre>
<ul>
<li>The <code>--output=parser.c</code> option directs Bison to write its code into
the file <code>parser.c</code> instead of the cryptic <code>yy.tab.c</code></li>
<li>If your grammar has shift-reduce or reduce-reduce conflicts, Bison
will happily output working code with some of the conflicting
actions suppressed. Always check for conflicts before proceeding.</li>
</ul>
<p>Filename: scanner.flex</p>
<pre><code class="language-c">%{
#include &quot;token.h&quot;
%}
DIGIT  [0-9]
LETTER [a-zA-Z]
%%
(&quot; &quot;|\t|\n) /* skip whitespace */
{DIGIT}+  { return TOKEN_INT; }
\+        { return TOKEN_PLUS; }
\-        { return TOKEN_MINUS; }
\*        { return TOKEN_MUL; }
\/        { return TOKEN_DIV; }
\(        { return TOKEN_LPAREN; }
\)        { return TOKEN_RPAREN; }
\;        { return TOKEN_SEMI; }
.         { return TOKEN_ERROR; }
%%
int yywrap() { return 1; }
</code></pre>
<p>Filename: parser.bison</p>
<pre><code class="language-c">%{
#include &lt;stdio.h&gt;
int yylex();
void yyerror (char const *s) {
    fprintf (stderr, &quot;%s\n&quot;, s);
}
%}
%token TOKEN_INT
%token TOKEN_PLUS
%token TOKEN_MINUS
%token TOKEN_MUL
%token TOKEN_DIV
%token TOKEN_LPAREN
%token TOKEN_RPAREN
%token TOKEN_SEMI
%token TOKEN_ERROR
%%
program : expr TOKEN_SEMI;
expr : expr TOKEN_PLUS term
| expr TOKEN_MINUS term
| term
;
term : term TOKEN_MUL factor
| term TOKEN_DIV factor
| factor
;
factor: TOKEN_MINUS factor
| TOKEN_LPAREN expr TOKEN_RPAREN
| TOKEN_INT
;
%%
</code></pre>
<p>Filename: main.c</p>
<pre><code class="language-c">#include &lt;stdio.h&gt;

extern int yyparse();

int main()
{
  if(yyparse()==0) {
    printf(&quot;Parse successful!\n&quot;);
  } else {
    printf(&quot;Parse failed.\n&quot;);
  }
}
</code></pre>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->
                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">
            </nav>

        </div>

        <!-- Livereload script (if served using the cli tool) -->
        <script type="text/javascript">
            const wsProtocol = location.protocol === 'https:' ? 'wss:' : 'ws:';
            const wsAddress = wsProtocol + "//" + location.host + "/" + "__livereload";
            const socket = new WebSocket(wsAddress);
            socket.onmessage = function (event) {
                if (event.data === "reload") {
                    socket.close();
                    location.reload();
                }
            };

            window.onbeforeunload = function() {
                socket.close();
            }
        </script>
        <script type="text/javascript">
            window.playground_copyable = true;
        </script>
        <script src="elasticlunr.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="mark.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="searcher.js" type="text/javascript" charset="utf-8"></script>
        <script src="clipboard.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="highlight.js" type="text/javascript" charset="utf-8"></script>
        <script src="book.js" type="text/javascript" charset="utf-8"></script>

        <!-- Custom JS scripts -->
        <script type="text/javascript">
        window.addEventListener('load', function() {
            window.setTimeout(window.print, 100);
        });
        </script>
    </body>
</html>
